# =============================================================================
# ‚úÖ STEP 5: TRAINING CONFIGURATION (Choose your path)
# =============================================================================
# FIRST try STANDARD version. If it crashes, use DEBUG version below.
# =============================================================================

from trl import SFTTrainer
from transformers import TrainingArguments, DataCollatorForSeq2Seq
import os

# =============================================================================
# üöÄ OPTION 1: STANDARD (Optimized - 2x faster) - USE THIS FIRST
# =============================================================================
"""
# Uncomment to use STANDARD version
os.environ["UNSLOTH_DISABLE_FUSED_CROSS_ENTROPY"] = "0"  # Keep optimizations ON

training_args = TrainingArguments(
    output_dir="./imdb-qlora",
    per_device_train_batch_size=1,
    gradient_accumulation_steps=8,
    warmup_steps=10,
    max_steps=60,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=5,
    save_steps=30,
    report_to="none",
    dataloader_num_workers=4,              # ‚úÖ Parallel loading (faster)
    remove_unused_columns=False,
)

data_collator = DataCollatorForSeq2Seq(    # ‚úÖ Handles padding
    tokenizer=tokenizer,
    model=model,
    padding=True,
)

model = FastLanguageModel.for_training(model)  # ‚úÖ Unsloth speed boost

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset['train'],
    args=training_args,
    data_collator=data_collator,
    dataset_text_field="text",
    max_seq_length=512,
    packing=True,                           # ‚úÖ Efficient sequence packing
)

print("‚úÖ STANDARD MODE: Optimized for speed")
"""











# =============================================================================
# üõ†Ô∏è OPTION 2: DEBUG (Safe mode - Use if STANDARD crashes)
# =============================================================================

# Uncomment this section if STANDARD version fails
"""
os.environ["UNSLOTH_DISABLE_FUSED_CROSS_ENTROPY"] = "1"  # Disable problematic feature

training_args = TrainingArguments(
    output_dir="./imdb-qlora",
    per_device_train_batch_size=1,
    gradient_accumulation_steps=8,
    warmup_steps=10,
    max_steps=60,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=5,
    save_steps=30,
    report_to="none",
    dataloader_num_workers=0,              # ‚ùå No multiprocessing (slower but safe)
    remove_unused_columns=False,
)

# Skip data_collator - let SFTTrainer handle it

# ‚ùå Skip Unsloth training mode (causes Dynamo crash)
# model = FastLanguageModel.for_training(model)  # Commented out

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset['train'],
    args=training_args,
    dataset_text_field="text",
    max_seq_length=512,
    packing=False,                          # ‚ùå No packing (simpler)
)

print("‚úÖ DEBUG MODE: Safe but slower")
"""

# =============================================================================
# üìã INSTRUCTIONS:
# 1. FIRST run STANDARD (uncomment Option 1, keep Option 2 commented)
# 2. If STANDARD crashes with Dynamo error ‚Üí switch to DEBUG
# 3. Run trainer.train() after uncommenting your chosen option
# =============================================================================

print("\nüöÄ Uncomment ONE option above, then run: trainer.train()")
